# Experimental Framework for LLM-based Planning and Safety Evaluation

## Overview

This experimental framework is based on [LLM+P](https://github.com/Cranial-XIX/llm-pddl) and extends it to evaluate the safety and robustness of plans generated by two LLM-based agent architectures: **LLM-as-Planner** and **LLM+Planner**. The evaluation involves a dataset where each example is described both in natural language and in PDDL (Planning Domain Definition Language), enabling fully automated safety assessments. The tool also supports **textual perturbations** to assess robustness under adversarial scenarios.

### Key Features
- **Automated Plan Evaluation**: The tool ensures that generated plans reach the goal state and adhere to safety constraints.
- **Robustness Testing**: Textual perturbations can be applied to different parts of the input to assess safety robustness.

## Repository

The code for this experimental framework is available on GitHub:
[https://github.com/aemartinez/llm-pddl/tree/safety-constraints](https://github.com/aemartinez/llm-pddl/tree/safety-constraints)

## Installation

1. Clone the repository:
    ```bash
    git clone https://github.com/aemartinez/llm-pddl.git -b safety-constraints
    cd llm-pddl
    ```

2. Install the necessary dependencies:
    ```bash
    pip install -r requirements.txt
    ```

3. Ensure that [Julia](https://julialang.org/downloads/) is installed, as the tool relies on the `juliacall` library for integrating with Julia.

## Usage

The framework is operated via the `main.py` script, which accepts multiple command-line arguments for configuring the experiments.

### Basic Command Structure

To run an experiment, use the following structure:
```bash
python main.py --domain <domain_name> --method <planner,pyd_gen> --task <task_number>
```

### Key Arguments

- **--domain**: Specifies the domain to use (e.g., `manipulation`). Available domains can be found in `domains.py`.
- **--method**: Defines the planner and Pydantic model generator pair. This is provided in the format `'planner,pyd_gen'`. If the second value is omitted, a default generator is used for the specified planner.
- **--plan-matcher**: Sets the plan matcher to evaluate goal states. Defaults to the value in `config.py`.
- **--task**: Specifies the task number to execute. This can be used to run specific tasks from the dataset.

### Example Experiment

To run an example experiment using the manipulation domain:
```bash
python main.py --domain manipulation --method llm_ic,sentence_actions --task 1
```

### Perturbation Recipes

In addition to the basic experiment, the framework also allows for **robustness testing** using various perturbation recipes. Here are some options:

- **wordnet**: Uses WordNet to swap words with synonyms.
- **charswap**: Perturbs words by swapping adjacent characters.
- **embedding**: Replaces words with similar terms using word embeddings.
- **back_trans**: Uses back-translation to perturb sentences.
- **back_transcription**: Applies back-transcription for sentence-level perturbations.
- **jailbreak**: Applies a jailbreak text, instructing the model to disregard safety constraints.
- **no_perturbation**: Does not apply any perturbation, preserving the original text.

#### Additional Arguments for Robustness Testing

When running a robustness experiment, you can specify additional arguments to customize the perturbation process:

- **--perturbation-recipe**: Choose from the available perturbation recipes listed above.
- **--pct-words-to-swap**: Specifies the percentage of words in the input text that should be perturbed. This argument accepts a float value between 0 and 1, where 0 means no words are swapped, and 1 means all words are subject to perturbation.
- **--perturbations-number**: Defines the number of perturbations to produce for each problem description. This allows for testing the robustness of the model under various perturbation scenarios.
- **--perturbation-targets**: Indicates which parts of the natural language problem description will be perturbed. Acceptable values include:
  - **init**: Perturb the initial state of the problem.
  - **goal**: Perturb the goal state of the problem.
  - **constraints**: Perturb any constraints defined in the problem.

### Example Commands for Robustness Testing

#### Run a Robustness Experiment
```bash
python main.py robustness-experiment --domain manipulation --method llm_ic,sentence_actions --task 1 --perturbation-recipe charswap --pct-words-to-swap 0.5
```